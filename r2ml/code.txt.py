#设置R镜像
# options(repos=structure(c(CRAN="https://mirrors.tuna.tsinghua.edu.cn/CRAN/")))
#一，简单制作
#二，布局
#三，细节优化，颜色搭配，线条设置，交互变化，标注的设置，可以借助
#图像布局
1. par()函数的参数详解
函数par()可以用来设置或者获取图形参数，par()本身（括号中不写任何参数）返回当前的图形参数设置（一个list）；若要设置图形参数，
则可用par(tag = value)的形式，其中tag的详细说明参见下面的列，value就是参数值。

2. layout()：mat用矩阵设置窗口的划分，矩阵的0元素表示该位置不画图，非0元素必须包括从1开始的连续的整数值，
比如：1……N，按非0元素的大小设置图形的顺序。widths用来设置窗口不同列的宽度，heights设置不同行的高度。
par()的mfcol,和mfrow参数也有类似layout的功能。layout()函数的一般形式为layout(mat)，
mat为一矩阵，mat元素的数量决定了一个output device被等分成几份相同元素为一块。
m<-matrix(c(1,1,2,1),2,2);m  #建立矩阵
layout(m,widths=c(2,1),heights=c(1,2)) #按照矩阵编号进行分割，编号相同的为同一块，宽度为2:1，高度为1:2
layout.show(2)

m<-matrix(0:3,2,2)#，注意，此矩阵中有0，0是不绘图的，可以查看一下效果
layout(m,c(1,3),c(1,3)) #行为1:3,列为1:3
layout.show(3)

3. split.screen函数

split.screen(c(1,2)):将当前的绘画装置分割为2块，分别为1号2号，可以通过screen(1)或screen(2)进行选择，
但此时的分割通常是按水平分割的，如果进行进详细的分割，可以用layout函数。
screen()选择绘图区域，screen(n = , new = TRUE)

eraser.screen() 清除选中的绘图区域，erase.screen(n = )

close.screen() 移除特定的选区，close.screen(n, all.screens = FALSE)

screen      Figs中的数字

split.screen()分割后，其余的函数才能使用。若无参数，则返回分割后小区域的编号，以向量的形式出现

close.screen退出分割，如果关闭当前的区域（即分割后的小区域），则进入下一个小区域，close.screen(all = TRUE)表示退出分割状态

#绘制简单图表练习
# 参考文章：一图胜千言
总体来说，有很多种绘制地图的方法,常用的方法主要是基于以下三种方法来绘制地图：
（1）ggplot2；（2）maps；（3）googleVis；还有一个程序包值得推荐：REmap






#重要算法
1，KNN （K近邻）：核心问题有两个，
一是依据怎样的标准测度与X的邻近关系，
二是应找到X的几个近邻，即依据怎么的原则确定K的取值。

太活跃的人基本上都是“看热闹”的闲人，她们经常在犹豫不决的左顾右盼中消耗自己。

缺点：样本类别间数量的不均衡（当扩大K时，将影响判断，加权改进（越近权重越大）），
超高的计算量（找出最近的K,就需要计算所有的样本距离，简约样本属性）

2，决策树：核心问题有两个
一是决策树的生长，即利用训练样本集完成决策树的建立过程（差异下降明显GINI系数，信息熵，最佳的分组变量，变量值中最佳的切割点）。
二是决策树的剪枝，即利用测试样本集对形成的决策树进行精简。
越深层处的节点所体现的数据特征就越显个性化，一般性就越差。当我们得到张三购买了某商品这一特殊性极强的规则，对于
预测判断某些人是否也会购买某产品还无价值导向性。
这条规则的精准性在训练样本中是毋庸置疑的，但失去一般性在测试样本中却显得毫无价值。

常用的修剪技术预修剪（清除分布，规定树的深度，设置节点最小的样本量）和后修剪（设置子决策树的最大误差，大于误差停止剪枝）
不要单纯以预测置信度为依据，也需要将错判损失考虑进来。


3，神经网络：
通常认为，人脑智慧的核心在于其连接机制。
大量神经元的巧妙连接，使人脑成为一个高度复杂的大规模非线性自适应系统。

加法器 , 激活函数（转化值域：[0,1]）

人工神经网络的建立过程时通过恰当的网络结构，探索输入和输出变量间复杂关系的过程，这是实现对新数据对象预测的前提。



4，支持向量机


5，聚类分组

数据客观小类的自然呈现

6，关联分析

一个有效的简单关联规则应具有较高的置信度和较高的支持度。
如果规则支持度较高，但置信度较低，则说明规则的可信程度差；
如果规则置信度较高但支持度较低，则说明规则的应用机会很少。
一个置信度较高但是支持度低普遍性较低的规则并没有太多的实际应用价值。
核心算法：apriori 和 eclat

第一步：找出频繁项集

第二步：依据频繁项集生成关联规则

7，网络分析
研究网络构成和网络成员间的相互影响，
是揭示事物相关性的另一个独特视角。
度和测地线距离 衡量一个节点的重要性。


想想那些不可思议的背后，有另一种道理。
抓取唐诗三百首，教你玩成语接龙。（提前首尾，拼音）
听说掌握2两个概率公式，缓解你99%的焦虑。
你真的太难了吗？













